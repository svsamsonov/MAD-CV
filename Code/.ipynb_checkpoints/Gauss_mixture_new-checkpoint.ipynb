{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.polynomial as P\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "#from sklearn.preprocessing import PolynomialFeatures\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import ZVnbrosse\n",
    "from potentials import GaussPotential,GaussMixture,GausMixtureIdent,GausMixtureSame,BananaShape\n",
    "from samplers import MCMC_sampler,Generate_train,ULA_light\n",
    "from baselines import set_function,construct_ESVM_kernel,GenerateSigma\n",
    "#from martingale import approx_q,approx_q_independent,test_traj\n",
    "from optimize import Run_eval_test,optimize_parallel_new \n",
    "from utils import *\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(k, x):\n",
    "    if k==0:\n",
    "        return 1.0\n",
    "    if k ==1:\n",
    "        return x\n",
    "    if k==2:\n",
    "        return (x**2 - 1)/np.sqrt(2)\n",
    "    c = np.zeros(k+1,dtype = float)\n",
    "    c[k] = 1.0\n",
    "    h = P.hermite_e.hermeval(x,c) / np.sqrt(sp.special.factorial(k)) \n",
    "    return h\n",
    "\n",
    "def compute_H(k,x):\n",
    "    return H(k[0],x[:,0])*H(k[1],x[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_q(X_train,Y_train,N_traj_train,lag,max_deg):\n",
    "    \"\"\"\n",
    "    Function to regress q functions on a polynomial basis;\n",
    "    Args:\n",
    "        X_train - train tralectory;\n",
    "        Y_train - function values;\n",
    "        N_traj_train - number of training trajectories;\n",
    "        lag - truncation point for coefficients, those for |p-l| > lag are set to 0;\n",
    "        max_deg - maximum degree of polynomial in regression\n",
    "    \"\"\"\n",
    "    dim = X_train[0,:].shape[0]\n",
    "    #print(\"dimension = \",dim)\n",
    "    coefs_poly = np.array([])\n",
    "    for i in range(lag):\n",
    "        x_all = np.array([])\n",
    "        y_all = np.array([])\n",
    "        for j in range(N_traj_train):\n",
    "            y = Y_train[j,i:,0]\n",
    "            if i == 0:\n",
    "                x = X_train[j,:]\n",
    "            else:\n",
    "                x = X_train[j,:-i]\n",
    "            #concatenate results\n",
    "            if x_all.size == 0:\n",
    "                x_all = x\n",
    "            else:\n",
    "                x_all = np.concatenate((x_all,x),axis = 0)\n",
    "            y_all = np.concatenate([y_all,y])\n",
    "        #should use polyfeatures here\n",
    "        #print(\"variance: \",np.var(y_all))\n",
    "        #print(y_all[:50])\n",
    "        poly = PolynomialFeatures(max_deg)\n",
    "        X_features = poly.fit_transform(x_all)\n",
    "        #print(X_features.shape)\n",
    "        lstsq_results = np.linalg.lstsq(X_features,y_all,rcond = None)\n",
    "        coefs = copy.deepcopy(lstsq_results[0])\n",
    "        coefs.resize((1,X_features.shape[1]))           \n",
    "        if coefs_poly.size == 0:\n",
    "            coefs_poly = copy.deepcopy(coefs)\n",
    "        else:\n",
    "            coefs_poly = np.concatenate((coefs_poly,coefs),axis=0)\n",
    "    return coefs_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_traj(coefs_poly_regr,gamma,r_seed,lag,d,cov,N_test,x0):\n",
    "    \"\"\"\n",
    "    function to perform 1-dimensional martingale decomposition\n",
    "    \"\"\"\n",
    "    X_test,Noise = generate_traj(x0,N_test,gamma,r_seed,d,cov)\n",
    "    test_stat_vanilla = np.zeros(N_test,dtype = float)\n",
    "    test_stat_vr = np.zeros_like(test_stat_vanilla)\n",
    "    #compute number of basis polynomials\n",
    "    basis_funcs = np.array([[1,0],[0,1],[1,1]])\n",
    "    num_basis_funcs = len(basis_funcs)\n",
    "    #compute polynomials of noise variables Z_l\n",
    "    poly_vals = np.zeros((num_basis_funcs,N_test), dtype = float)\n",
    "    for k in range(len(basis_funcs)):\n",
    "        poly_vals[k,:] = compute_H(basis_funcs[k],Noise)\n",
    "    #initialize function\n",
    "    f_vals_vanilla = np.sum(X_test**2,axis=1)\n",
    "    #array to store control variates values\n",
    "    cvfs = np.zeros_like(f_vals_vanilla)\n",
    "    #compute coeffitients bar_a\n",
    "    bar_a_0_1 = np.zeros((lag,N_test),dtype=float)\n",
    "    bar_a_1_0 = np.zeros_like(bar_a_0_1)\n",
    "    bar_a_1_1 = np.zeros_like(bar_a_0_1)\n",
    "    for i in range(lag):\n",
    "        #coefficients with H_0_1\n",
    "        bar_a_0_1[i,1:] = coefs_poly_regr[i,1]*cov[0,1]*np.sqrt(gamma)*sigma(X_test[:-1])[:,0]+\\\n",
    "                        coefs_poly_regr[i,2]*cov[1,1]*np.sqrt(gamma)*sigma(X_test[:-1])[:,1]+\\\n",
    "                        2*coefs_poly_regr[i,3]*cov[0,1]*np.sqrt(gamma)*sigma(X_test[:-1])[:,0]*(X_test[:-1]+gamma*b(X_test[:-1]))[:,0]+\\\n",
    "                        coefs_poly_regr[i,4]*(((X_test[:-1]+gamma*b(X_test[:-1]))[:,0])*sigma(X_test[:-1])[:,1]*np.sqrt(gamma)*cov[1,1] +\\\n",
    "                                             ((X_test[:-1]+gamma*b(X_test[:-1]))[:,1])*sigma(X_test[:-1])[:,0]*np.sqrt(gamma)*cov[0,1])+\\\n",
    "                        2*coefs_poly_regr[i,5]*cov[1,1]*np.sqrt(gamma)*sigma(X_test[:-1])[:,1]*(X_test[:-1]+gamma*b(X_test[:-1]))[:,1]\n",
    "        bar_a_0_1[i,0] = coefs_poly_regr[i,1]*cov[0,1]*np.sqrt(gamma)*sigma(x0)[0]+\\\n",
    "                        coefs_poly_regr[i,2]*cov[1,1]*np.sqrt(gamma)*sigma(x0)[1]+\\\n",
    "                        2*coefs_poly_regr[i,3]*cov[0,1]*np.sqrt(gamma)*sigma(x0)[0]*(x0+gamma*b(x0))[0]+\\\n",
    "                        coefs_poly_regr[i,4]*(((x0+gamma*b(x0))[0])*sigma(x0)[1]*np.sqrt(gamma)*cov[1,1] +\\\n",
    "                                             ((x0+gamma*b(x0))[1])*sigma(x0)[0]*np.sqrt(gamma)*cov[0,1])+\\\n",
    "                        2*coefs_poly_regr[i,5]*cov[1,1]*np.sqrt(gamma)*sigma(x0)[1]*(x0+gamma*b(x0))[1]\n",
    "        #coefficients with H_1_0\n",
    "        bar_a_1_0[i,1:] = coefs_poly_regr[i,1]*cov[0,0]*np.sqrt(gamma)*sigma(X_test[:-1])[:,0]+\\\n",
    "                        coefs_poly_regr[i,2]*cov[0,1]*np.sqrt(gamma)*sigma(X_test[:-1])[:,1]+\\\n",
    "                        2*coefs_poly_regr[i,3]*cov[0,0]*np.sqrt(gamma)*sigma(X_test[:-1])[:,0]*(X_test[:-1]+gamma*b(X_test[:-1]))[:,0]+\\\n",
    "                        coefs_poly_regr[i,4]*(((X_test[:-1]+gamma*b(X_test[:-1]))[:,0])*sigma(X_test[:-1])[:,1]*np.sqrt(gamma)*cov[0,1] +\\\n",
    "                                             ((X_test[:-1]+gamma*b(X_test[:-1]))[:,1])*sigma(X_test[:-1])[:,0]*np.sqrt(gamma)*cov[0,0])+\\\n",
    "                        2*coefs_poly_regr[i,5]*cov[0,1]*np.sqrt(gamma)*sigma(X_test[:-1])[:,1]*(X_test[:-1]+gamma*b(X_test[:-1]))[:,1]\n",
    "        bar_a_1_0[i,0] = coefs_poly_regr[i,1]*cov[0,0]*np.sqrt(gamma)*sigma(x0)[0]+\\\n",
    "                        coefs_poly_regr[i,2]*cov[0,1]*np.sqrt(gamma)*sigma(x0)[1]+\\\n",
    "                        2*coefs_poly_regr[i,3]*cov[0,0]*np.sqrt(gamma)*sigma(x0)[0]*(x0+gamma*b(x0))[0]+\\\n",
    "                        coefs_poly_regr[i,4]*(((x0+gamma*b(x0))[0])*sigma(x0)[1]*np.sqrt(gamma)*cov[0,1] +\\\n",
    "                                             ((x0+gamma*b(x0))[1])*sigma(x0)[0]*np.sqrt(gamma)*cov[0,0]) +\\\n",
    "                        2*coefs_poly_regr[i,5]*cov[0,1]*np.sqrt(gamma)*sigma(x0)[1]*(x0+gamma*b(x0))[1]\n",
    "        #second-order coefficients\n",
    "        bar_a_1_1[i,1:] = 2*coefs_poly_regr[i,3]*gamma*(sigma(X_test[:-1])[:,0])**2*cov[0,0]*cov[0,1]+\\\n",
    "                        coefs_poly_regr[i,4]*gamma*(sigma(X_test[:-1])[:,0])*(sigma(X_test[:-1])[:,1])*(cov[0,1]**2 + cov[0,0]*cov[1,1])+\\\n",
    "                        2*coefs_poly_regr[i,5]*gamma*(sigma(X_test[:-1])[:,1])**2*cov[1,1]*cov[0,1]\n",
    "        bar_a_1_1[i,0] = 2*coefs_poly_regr[i,3]*gamma*(sigma(x0)[0])**2*cov[0,0]*cov[0,1]+\\\n",
    "                        coefs_poly_regr[i,4]*gamma*(sigma(x0)[0])*(sigma(x0)[1])*(cov[0,1]**2 + cov[0,0]*cov[1,1])+\\\n",
    "                        2*coefs_poly_regr[i,5]*gamma*(sigma(x0)[1])**2*cov[1,1]*cov[0,1]\n",
    "    bar_a_1_0 = bar_a_1_0*poly_vals[0,:]\n",
    "    bar_a_0_1 = bar_a_0_1*poly_vals[1,:]\n",
    "    bar_a_1_1 = bar_a_1_1*poly_vals[2,:]\n",
    "    #compute martingale sums\n",
    "    M_n_0_1 = 0.0\n",
    "    M_n_1_0 = 0.0\n",
    "    M_n_1_1 = 0.0\n",
    "    for l in range(N_test):\n",
    "        for r in range(min(N_test-l,lag)):\n",
    "            M_n_0_1 += bar_a_0_1[r,l]\n",
    "            M_n_1_0 += bar_a_1_0[r,l]\n",
    "            M_n_1_1 += bar_a_1_1[r,l]\n",
    "    return np.mean(f_vals_vanilla), np.mean(f_vals_vanilla)-(M_n_0_1 + M_n_1_0)/N_test, np.mean(f_vals_vanilla)-(M_n_0_1 + M_n_1_0 + M_n_1_1)/N_test\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = np.array([10,20,30,40,50,60,70,80,90,100])\n",
    "vr_rates_dep = []\n",
    "vr_rates_indep = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_burn = 1*10**4 # Burn in period\\n\",\n",
    "N_train = 2*10**4 # Number of samples on which we optimize\\n\"\n",
    "N_test = 2*10**3 # Number of samples\\n\",\n",
    "step = 0.1 # Step size\\n\",\n",
    "n_traj_train = 10\n",
    "n_traj_test = 24 # Number of independent MCMC trajectories for test\\n\",\n",
    "f_type = \"sum_squares\"\n",
    "K_max = 2 #max degree of Hermite polynomial\\n\",\n",
    "S_max = 2 #max degree of polynomial during regression stage\\n\",\n",
    "lag = 100 #maximal lag order\\n\",\n",
    "b_n_train = 20 #lag-window size\\n\",\n",
    "b_n_test = int(np.round(N_test**(0.33)))\n",
    "print(b_n_test)\n",
    "degree = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "mu = 0.5*np.array([1.0,1.0],dtype = float)\n",
    "#mu_1 = np.array([-1.0])\n",
    "#mu_2 = np.array([1.0])\n",
    "#Sigma_1 = np.array([[1.0]])\n",
    "#Sigma_2 = np.array([[1.0]])\n",
    "Sigma = GenerateSigma(d,rand_seed = 777,eps = 0.1) #covariation matrix \n",
    "p = 0.5\n",
    "#Cur_pot = GausMixtureSame(Sigma,mu,p)\n",
    "#Cur_pot = GaussMixture(Sigma_1,Sigma_2,mu_1,mu_2,p)\n",
    "Cur_pot = GausMixtureIdent(mu,p)\n",
    "r_seed = 777\n",
    "x0 = np.array([0.0,0.0])\n",
    "fixed_start = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose sampler type (currently only ULA is maintained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_seed = 777\n",
    "traj = np.zeros((n_traj_train,N_train,d),dtype = float)\n",
    "for i in range(n_traj_train):\n",
    "    cur_traj = ULA_light(r_seed+i,Cur_pot,step, N_burn, N_train, d, return_noise = False, x0 = x0, fixed_start = fixed_start)\n",
    "    traj[i] = copy.deepcopy(cur_traj)\n",
    "print(traj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_arr = np.array([1]) # Taking the second index (not intercept)\n",
    "params = None    \n",
    "f_vals = set_function(f_type,traj,inds_arr,params) \n",
    "#f_vals = traj[:,:,0]\n",
    "#f_vals = np.expand_dims(f_vals, axis=2)\n",
    "print(f_vals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_traj_train_adv = 5*10**4\n",
    "r_seed = 7771453\n",
    "traj_adv = np.zeros((n_traj_train_adv,lag,d),dtype = float)\n",
    "nbcores = multiprocessing.cpu_count()\n",
    "trav = Pool(nbcores)\n",
    "res = trav.starmap(ULA_light, [(r_seed+i,Cur_pot,step, 100, lag, d, False,x0, False) for i in range (n_traj_train_adv)])\n",
    "trav.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_adv = np.zeros((n_traj_train_adv,lag,d),dtype = float)\n",
    "for i in range(n_traj_train_adv):\n",
    "    traj_adv[i] = copy.deepcopy(res[i])\n",
    "print(traj_adv.shape)\n",
    "inds_arr = np.array([0]) # Taking the second index (not intercept)\n",
    "params = None  \n",
    "f_vals_adv = set_function(f_type,traj_adv,inds_arr,params)\n",
    "print(f_vals_adv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate baselines (EVM and ESVM methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = {\"sampler\":\"ULA\",\"burn_type\":\"full\",\"main_type\":\"full\"} # Sampling method\n",
    "\n",
    "if sampler[\"sampler\"] == \"ULA\":\n",
    "    res = Generate_train(n_traj_train, sampler, Cur_pot, step, N_burn, N_train, d)\n",
    "    res = np.asarray(res)\n",
    "    traj_evm,traj_grad = res[:,0,:,:],res[:,1,:,:]\n",
    "else:\n",
    "    raise \"You should use ULA!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traj.shape)\n",
    "inds_arr = np.array([0])#Taking the second index\n",
    "params = None\n",
    "f_vals_evm = set_function(f_type,traj_evm,inds_arr,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f_vals_evm)\n",
    "print(f_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_train_spec = construct_ESVM_kernel(N_train,b_n_train) #weight matrix for train\n",
    "W_test_spec = construct_ESVM_kernel(N_test,b_n_test) #weight matrix for test\n",
    "opt_structure_train = {\n",
    "    \"W\":W_train_spec,\n",
    "    \"n_restarts\": 3, # Number of restarts during optimization,\n",
    "    \"sigma\": 1.0, # Deviation of starting points\n",
    "    \"tol\": 1e-5, # Tolerance (for the norm of gradient)\n",
    "    \"alpha\": 0.0, # Ridge penalty for 2nd order control functionals\n",
    "    \"beta\": 10000.0 # smoothing parameter in the softmax\n",
    "}\n",
    "methods = [\"ESVM\",\"EVM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_dict = optimize_parallel_new(degree,inds_arr,f_vals_evm,traj_evm,traj_grad,opt_structure_train,methods)\n",
    "print(coef_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary and put respective matrices into it\n",
    "test_params = {\n",
    "    \"W\":W_test_spec,\n",
    "    \"step\":step,\n",
    "    \"burn_in\":N_burn,\n",
    "    \"n_test\":N_test,\n",
    "    \"dim\":d\n",
    "}\n",
    "\n",
    "nbcores = multiprocessing.cpu_count()\n",
    "trav = Pool(nbcores)\n",
    "res = trav.starmap(Run_eval_test, [(i,degree,sampler,methods,inds_arr,Cur_pot,test_params,coef_dict,params,f_type) for i in range (n_traj_test)])\n",
    "trav.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_enh = ['Vanilla'] + methods\n",
    "print(methods_enh)\n",
    "ints_result = {key: [] for key in methods_enh}\n",
    "vars_result = {key: [] for key in methods_enh}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(res)):\n",
    "    for j in range(len(methods_enh)):\n",
    "        ints_result[methods_enh[j]].append(res[i][0][methods_enh[j]][0])\n",
    "        vars_result[methods_enh[j]].append(res[i][1][methods_enh[j]][0])\n",
    "for key in methods_enh:\n",
    "    ints_result[key] = np.asarray(ints_result[key])\n",
    "    vars_result[key] = np.asarray(vars_result[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli:: Optimize coefficients by solving regression with polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#polynomial coefficients\n",
    "coefs_poly = approx_q(traj,f_vals,n_traj_train,lag,S_max)\n",
    "print(coefs_poly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_poly_indep = approx_q_independent(traj_adv,f_vals_adv,n_traj_train_adv,lag,S_max)\n",
    "print(coefs_poly.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use theoretically computed coefficients in regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coefs_poly.shape)\n",
    "print(coefs_poly)\n",
    "coefs_poly_theor = np.zeros_like(coefs_poly)\n",
    "for ind in range(len(coefs_poly_theor)):\n",
    "    if ind == 0:\n",
    "        coefs_poly_theor[ind,0] = 0\n",
    "    else:\n",
    "        coefs_poly_theor[ind,0] = d*(1-(1-step)**(2*ind))/(1-step/2)   \n",
    "    coefs_poly_theor[ind,3] = (1-step)**(2*ind)\n",
    "    coefs_poly_theor[ind,5] = (1-step)**(2*ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test our regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_lag = 1\n",
    "N_pts = 100\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Testing regression model\",fontsize=20)\n",
    "plt.plot(traj[0,cur_lag:N_pts],color='r',label='true function')\n",
    "plt.plot(P.polynomial.polyval(traj[0,:N_pts-cur_lag],coefs_poly[cur_lag,:]),color='g',label = 'practical approximation')\n",
    "#plt.plot(P.polynomial.polyval(X_train[0,:N_pts-cur_lag],coefs_poly_theor[cur_lag,:]),color='b',label = 'theoretical approximation')\n",
    "plt.legend(loc = 'lower right',fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seed = 1453\n",
    "nbcores = multiprocessing.cpu_count()\n",
    "trav = Pool(nbcores)\n",
    "res_dep = trav.starmap(test_traj, [(Cur_pot,coefs_poly,step,test_seed+i,lag,K_max,S_max,N_burn,N_test,d,f_type,inds_arr,params,x0,fixed_start) for i in range (n_traj_test)])\n",
    "trav.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seed = 1453\n",
    "nbcores = multiprocessing.cpu_count()\n",
    "trav = Pool(nbcores)\n",
    "res_indep = trav.starmap(test_traj, [(Cur_pot,coefs_poly_indep,step,test_seed+i,lag,K_max,S_max,N_burn,N_test,d,f_type,inds_arr,params,x0,fixed_start) for i in range (n_traj_test)])\n",
    "trav.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_new_dep = np.asarray(res_dep)\n",
    "res_new_indep = np.asarray(res_indep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_vanilla_dep = np.var(res_new_dep[:,0,:],axis = 0)\n",
    "vars_adj_dep = np.var(res_new_dep[:,1,:],axis = 0)\n",
    "vr_rate_dep = vars_vanilla_dep[-1]/vars_adj_dep[-1]\n",
    "print(vr_rate_dep)\n",
    "\n",
    "vars_vanilla_indep = np.var(res_new_indep[:,0,:],axis = 0)\n",
    "vars_adj_indep = np.var(res_new_indep[:,1,:],axis = 0)\n",
    "vr_rate_indep = vars_vanilla_indep[-1]/vars_adj_indep[-1]\n",
    "print(vr_rate_indep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr_rates_dep.append(vr_rate_dep)\n",
    "vr_rates_indep.append(vr_rate_indep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vr_rates_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr_rates_dep = np.asarray(vr_rates_dep)\n",
    "vr_rates_indep = np.asarray(vr_rates_indep)\n",
    "#np.save('vr_rate_dep_gmm_quadratic.npy',vr_rates_dep)\n",
    "#np.save('vr_rate_indep_gmm_quadratic.npy',vr_rates_indep)\n",
    "print(vr_rates_dep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,8))\n",
    "# plot the index for the x-values\n",
    "#plt.plot(lags,vr_rates_dep/(lags*8), marker='o', linestyle='--', color='r', label='Train on dependent trajectories') \n",
    "plt.plot(lags,vr_rates_indep/(lags*8), marker='o', linestyle='--', color='b') #,label='Train on independent trajectories') \n",
    "#plt.xlabel('lag',fontsize = 18)\n",
    "#plt.ylabel('cost',fontsize = 18) \n",
    "#plt.title('VR cost for MDCV, Gaussian distribution, quadratic target',fontsize = 20)\n",
    "plt.grid(linestyle='--', linewidth=1.0)\n",
    "#plt.legend() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "# plot the index for the x-values\n",
    "#plt.plot(lags[:8],vr_rates_dep, marker='o', linestyle='--', color='r', label='Train on dependent trajectories') \n",
    "plt.plot(lags[:8],vr_rates_indep, marker='o', linestyle='--', color='b', label='Train on independent trajectories') \n",
    "#plt.xlabel('lag',fontsize = 18)\n",
    "#plt.ylabel('VR rate',fontsize = 18) \n",
    "#plt.title('VR rates for MDCV, Gaussian Mixture, quadratic target',fontsize = 20)\n",
    "plt.grid(linestyle='--', linewidth=1.0)\n",
    "plt.legend() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"\"\n",
    "labels = ['Vanilla\\n ULA', 'ULA \\nwith MDCV', 'ULA \\nwith EVM','ULA\\nwith ESVM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [ints_result['Vanilla'][:,0],res_new[:,1,-1],ints_result['EVM'][:,0],ints_result['ESVM'][:,0]] \n",
    "boxplot_ind(data, title, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"\"\n",
    "labels = ['ULA \\nwith MDCV', 'ULA \\nwith EVM','ULA\\nwith ESVM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [res_new[:,1,-1],ints_result['EVM'][:,0],ints_result['ESVM'][:,0]] \n",
    "boxplot_ind(data, title, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
